{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# !pip install mxnet\n","# !pip install gluonnlp pandas tqdm\n","# !pip install sentencepiece\n","# !pip install transformers\n","# !pip install torch"],"metadata":{"id":"HkfyD8sNpNnC","collapsed":true,"executionInfo":{"status":"ok","timestamp":1731747652013,"user_tz":-540,"elapsed":334,"user":{"displayName":"gt","userId":"06746045531472583665"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install sentence-transformers"],"metadata":{"id":"8P-cf0_xZjYF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import BertForQuestionAnswering, BertTokenizer\n","import torch"],"metadata":{"id":"oJLf6e_sne2S","executionInfo":{"status":"ok","timestamp":1731747670976,"user_tz":-540,"elapsed":18652,"user":{"displayName":"gt","userId":"06746045531472583665"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywq56f6YnlCb","outputId":"84a4da63-8d63-4690-faad-ac5c99735bcc","collapsed":true,"executionInfo":{"status":"ok","timestamp":1731750803833,"user_tz":-540,"elapsed":1614,"user":{"displayName":"gt","userId":"06746045531472583665"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c7abRZ22UTi","executionInfo":{"status":"ok","timestamp":1731747704113,"user_tz":-540,"elapsed":15896,"user":{"displayName":"gt","userId":"06746045531472583665"}},"outputId":"e715dc55-a52e-486e-ff4a-6a971ed731cb"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import json\n","from collections import Counter\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity"],"metadata":{"id":"mmg52sKl2c1G","executionInfo":{"status":"ok","timestamp":1731750347917,"user_tz":-540,"elapsed":341,"user":{"displayName":"gt","userId":"06746045531472583665"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def f1_score(ground_truth, prediction):\n","    # Split the answers into word tokens\n","    ground_truth_tokens = ground_truth.split()\n","    prediction_tokens = prediction.split()\n","\n","    # Count the occurrences of each word\n","    ground_truth_counter = Counter(ground_truth_tokens)\n","    prediction_counter = Counter(prediction_tokens)\n","\n","    # Calculate the number of common tokens\n","    common_tokens = ground_truth_counter & prediction_counter\n","    num_common_tokens = sum(common_tokens.values())\n","\n","    # If there are no common tokens, return F1 score of 0\n","    if num_common_tokens == 0:\n","        return 0.0\n","\n","    # Precision: Proportion of predicted tokens that are correct\n","    precision = num_common_tokens / len(prediction_tokens)\n","\n","    # Recall: Proportion of ground truth tokens that are predicted\n","    recall = num_common_tokens / len(ground_truth_tokens)\n","\n","    # F1 Score: Harmonic mean of precision and recall\n","    f1 = 2 * (precision * recall) / (precision + recall)\n","\n","    return f1\n","\n","st_model = SentenceTransformer('all-MiniLM-L6-v2')"],"metadata":{"id":"aHEmbvg1_sR4","executionInfo":{"status":"ok","timestamp":1731750807585,"user_tz":-540,"elapsed":1495,"user":{"displayName":"gt","userId":"06746045531472583665"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["conv_qa_path = \"drive/MyDrive/24_1_DL/Final_Project/conversation_qa.json\"\n","doc_qa_path = \"drive/MyDrive/24_1_DL/Final_Project/document_qa.json\"\n","\n","with open(conv_qa_path, \"r\", encoding=\"utf-8\") as conv_qa, open(doc_qa_path, \"r\", encoding=\"utf-8\") as doc_qa:\n","  data_conv = json.load(conv_qa)\n","  data_doc = json.load(doc_qa)\n","\n","  if len(data_conv['items']) != len(data_doc['items']):\n","    print(\"WTF\")\n","    raise ValueError\n","\n","  conv_f1_scores, doc_f1_scores = [], []\n","  conv_similarities, doc_similarities = [], []\n","\n","  for idx in range(len(data_conv['items'])):\n","    conv_item = data_conv['items'][idx]\n","    doc_item = data_doc['items'][idx]\n","\n","    if conv_item['question'] != doc_item['question'] or conv_item['answer'] != doc_item['answer']:\n","      print(\"WTF\")\n","      raise ValueError\n","\n","    # conversation-based\n","    paragraph = conv_item['conv']\n","    question = conv_item['question']\n","    answer = conv_item['answer'].lower()\n","\n","    question_tokens = tokenizer.tokenize('[CLS]' + question + '[SEP]')\n","    paragraph_tokens = tokenizer.tokenize(paragraph + '[SEP]')\n","    tokens = question_tokens + paragraph_tokens\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","    segment_ids = [0] * len(question_tokens)\n","    segment_ids += [1] * len(paragraph_tokens)\n","\n","    input_ids = torch.tensor([input_ids])\n","    segment_ids = torch.tensor([segment_ids])\n","\n","    output = model(input_ids, token_type_ids=segment_ids)\n","\n","    start_scores, end_scores = output['start_logits'], output['end_logits']\n","\n","    conv_start_index = torch.argmax(start_scores)\n","    conv_end_index = torch.argmax(end_scores)\n","\n","    conv_predicted_tokens = tokens[conv_start_index:conv_end_index+1]\n","    conv_predicted_answer = tokenizer.decode(tokenizer.convert_tokens_to_ids(conv_predicted_tokens)).lower()\n","\n","    conv_f1 = f1_score(answer, conv_predicted_answer)\n","    conv_f1_scores.append(conv_f1)\n","\n","    embedding_answer = st_model.encode(answer)\n","    embedding_pred_answer = st_model.encode(conv_predicted_answer)\n","\n","    conv_similarity = float(cosine_similarity([embedding_answer], [embedding_pred_answer])[0][0])\n","    conv_similarities.append(conv_similarity)\n","\n","    # document-based\n","    paragraph = doc_item['doc']\n","    question = doc_item['question']\n","    answer = doc_item['answer'].lower()\n","\n","    question_tokens = tokenizer.tokenize('[CLS]' + question + '[SEP]')\n","    paragraph_tokens = tokenizer.tokenize(paragraph + '[SEP]')\n","    tokens = question_tokens + paragraph_tokens\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","    segment_ids = [0] * len(question_tokens)\n","    segment_ids += [1] * len(paragraph_tokens)\n","\n","    input_ids = torch.tensor([input_ids])\n","    segment_ids = torch.tensor([segment_ids])\n","\n","    output = model(input_ids, token_type_ids=segment_ids)\n","\n","    start_scores, end_scores = output['start_logits'], output['end_logits']\n","\n","    doc_start_index = torch.argmax(start_scores)\n","    doc_end_index = torch.argmax(end_scores)\n","\n","    doc_predicted_tokens = tokens[doc_start_index:doc_end_index+1]\n","    doc_predicted_answer = tokenizer.decode(tokenizer.convert_tokens_to_ids(doc_predicted_tokens)).lower()\n","\n","    doc_f1 = f1_score(answer, doc_predicted_answer)\n","    doc_f1_scores.append(doc_f1)\n","\n","    embedding_answer = st_model.encode(answer)\n","    embedding_pred_answer = st_model.encode(doc_predicted_answer)\n","\n","    doc_similarity = float(cosine_similarity([embedding_answer], [embedding_pred_answer])[0][0])\n","    doc_similarities.append(doc_similarity)\n","\n","    # Comparing each results\n","    print(f'\\n------- Example {idx} -------')\n","    print(f'Question {idx}: {question}')\n","    print(f'Original answer: {answer}')\n","    print(f'Predicted answer(conv): {conv_predicted_answer}')\n","    print(f'Predicted answer(doc): {doc_predicted_answer}')\n","    print(f'F1 score(conv): {round(conv_f1, 2)}')\n","    print(f'F1 score(doc): {round(doc_f1, 2)}')\n","    print(f'Similarity(conv): {round(conv_similarity, 2)}')\n","    print(f'Similarity(doc): {round(doc_similarity, 2)}')\n","\n","  print(f'\\n\\nAverage F1 score(conv): {sum(conv_f1_scores) / len(conv_f1_scores)}')\n","  print(f'Average F1 score(doc): {sum(doc_f1_scores) / len(doc_f1_scores)}')\n","  print(f'Average Similarity(conv): {sum(conv_similarities) / len(conv_similarities)}')\n","  print(f'Average Similarity(doc): {sum(doc_similarities) / len(doc_similarities)}')\n"],"metadata":{"id":"7ek0qybiLfJ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731751869207,"user_tz":-540,"elapsed":823627,"user":{"displayName":"gt","userId":"06746045531472583665"}},"outputId":"999de1b1-1e9e-4e81-a584-90ce21e56c8e"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","------- Example 0 -------\n","Question 0: What was the most number of people Tom has met during a holiday?\n","Original answer: 25\n","Predicted answer(conv): 25\n","Predicted answer(doc): 25\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 1 -------\n","Question 1: Where does Tom plan to go for a hike?\n","Original answer: diablo\n","Predicted answer(conv): diablo\n","Predicted answer(doc): diablo\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 2 -------\n","Question 2: When was the last time Jerry saw his old friend?\n","Original answer: june\n","Predicted answer(conv): june\n","Predicted answer(doc): june\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 3 -------\n","Question 3: What does Tom think about rain?\n","Original answer: gloomy\n","Predicted answer(conv): \n","Predicted answer(doc): surprising that the rain started early this year\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.25\n","Similarity(doc): 0.26\n","\n","------- Example 4 -------\n","Question 4: What color does Tom associate with tranquility?\n","Original answer: blue\n","Predicted answer(conv): blue\n","Predicted answer(doc): blue\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 5 -------\n","Question 5: What has Tom done to try and find his missing cat?\n","Original answer: banged dish\n","Predicted answer(conv): banging her catfood dish and shouting her name\n","Predicted answer(doc): banging her catfood dish and shouting her name\n","F1 score(conv): 0.2\n","F1 score(doc): 0.2\n","Similarity(conv): 0.54\n","Similarity(doc): 0.54\n","\n","------- Example 6 -------\n","Question 6: What type of massage is Tom getting?\n","Original answer: traditional\n","Predicted answer(conv): traditional kind\n","Predicted answer(doc): traditional kind\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.86\n","Similarity(doc): 0.86\n","\n","------- Example 7 -------\n","Question 7: What type of food does Jerry generally love?\n","Original answer: noodle soups\n","Predicted answer(conv): noodle soups\n","Predicted answer(doc): noodle soups\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 8 -------\n","Question 8: Where is Jerry planning to travel in December?\n","Original answer: hawaii\n","Predicted answer(conv): hawaii\n","Predicted answer(doc): hawaii\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 9 -------\n","Question 9: What type of Christmas tree did Tom choose?\n","Original answer: artificial\n","Predicted answer(conv): eco - friendly\n","Predicted answer(doc): eco - friendly\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.33\n","Similarity(doc): 0.33\n","\n","------- Example 10 -------\n","Question 10: What does Jerry do for work?\n","Original answer: horse vaulting\n","Predicted answer(conv): train and compete in horse vaulting\n","Predicted answer(doc): train and compete in horse vaulting.'tom said'oh wow. were you born a horse, or were you turned into one?'jerry said'lol you're too funny.'tom said'just kidding. that sounds pretty cool! is it your job?'jerry said'yeah, but i part time work on a farm\n","F1 score(conv): 0.5\n","F1 score(doc): 0.05\n","Similarity(conv): 0.86\n","Similarity(doc): 0.59\n","\n","------- Example 11 -------\n","Question 11: What is Jerry’s favorite flower?\n","Original answer: lotus\n","Predicted answer(conv): gerbera\n","Predicted answer(doc): lotus\n","F1 score(conv): 0.0\n","F1 score(doc): 1.0\n","Similarity(conv): 0.26\n","Similarity(doc): 1.0\n","\n","------- Example 12 -------\n","Question 12: Where does Jerry live?\n","Original answer: tokyo\n","Predicted answer(conv): tokyo, japan\n","Predicted answer(doc): tokyo, japan\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.92\n","Similarity(doc): 0.92\n","\n","------- Example 13 -------\n","Question 13: What movie did Tom watch last weekend?\n","Original answer: the parasite\n","Predicted answer(conv): the parasite\n","Predicted answer(doc): the parasite\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 14 -------\n","Question 14: What did Jerry have at the local cafe?\n","Original answer: double espresso\n","Predicted answer(conv): double espresso\n","Predicted answer(doc): double espresso\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 15 -------\n","Question 15: Where is Jerry currently based?\n","Original answer: la\n","Predicted answer(conv): la\n","Predicted answer(doc): la\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 16 -------\n","Question 16: Where is Tom going for the holidays?\n","Original answer: bahamas\n","Predicted answer(conv): the bahamas\n","Predicted answer(doc): the bahamas\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.96\n","Similarity(doc): 0.96\n","\n","------- Example 17 -------\n","Question 17: What did Jerry make with an air fryer?\n","Original answer: donuts and samosas\n","Predicted answer(conv): donuts and samosas\n","Predicted answer(doc): donuts and samosas\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 18 -------\n","Question 18: Where does Jerry live?\n","Original answer: bottom of the valley\n","Predicted answer(conv): the bottom of the valley\n","Predicted answer(doc): the bottom of the valley\n","F1 score(conv): 0.89\n","F1 score(doc): 0.89\n","Similarity(conv): 0.99\n","Similarity(doc): 0.99\n","\n","------- Example 19 -------\n","Question 19: What is Tom’s favorite type of ice cream?\n","Original answer: vanilla\n","Predicted answer(conv): vanilla\n","Predicted answer(doc): vanilla\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 20 -------\n","Question 20: What movie did Jerry watch last night?\n","Original answer: terminator\n","Predicted answer(conv): terminator\n","Predicted answer(doc): terminator\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 21 -------\n","Question 21: What does Jerry plan to buy on Black Friday?\n","Original answer: fitbit\n","Predicted answer(conv): fitbit\n","Predicted answer(doc): fitbit\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 22 -------\n","Question 22: What activity has Jerry gotten into lately?\n","Original answer: yoga\n","Predicted answer(conv): yoga\n","Predicted answer(doc): yoga\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 23 -------\n","Question 23: Where is Jerry going for the holidays?\n","Original answer: mexico\n","Predicted answer(conv): mexico\n","Predicted answer(doc): mexico\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 24 -------\n","Question 24: What kind of classifier is Tom working on?\n","Original answer: hate speech\n","Predicted answer(conv): a new classifier for hate speech\n","Predicted answer(doc): a new classifier for hate speech\n","F1 score(conv): 0.5\n","F1 score(doc): 0.5\n","Similarity(conv): 0.66\n","Similarity(doc): 0.66\n","\n","------- Example 25 -------\n","Question 25: What does Jerry do as a fish groomer?\n","Original answer: tank cleaning\n","Predicted answer(conv): take care of people's fish\n","Predicted answer(doc): take care of people's fish\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.4\n","Similarity(doc): 0.4\n","\n","------- Example 26 -------\n","Question 26: What swimming style is Jerry good at?\n","Original answer: backstroke\n","Predicted answer(conv): on my back\n","Predicted answer(doc): swimming on my back\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.25\n","Similarity(doc): 0.56\n","\n","------- Example 27 -------\n","Question 27: What did Tom have for breakfast?\n","Original answer: eggs and hash browns\n","Predicted answer(conv): eggs and hash browns\n","Predicted answer(doc): eggs and hash browns\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 28 -------\n","Question 28: What class is Jerry attending?\n","Original answer: sewing\n","Predicted answer(conv): sewing\n","Predicted answer(doc): sewing\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 29 -------\n","Question 29: Which cave did Jerry hike in Vietnam?\n","Original answer: son doong\n","Predicted answer(conv): son doong cave\n","Predicted answer(doc): son doong cave\n","F1 score(conv): 0.8\n","F1 score(doc): 0.8\n","Similarity(conv): 0.75\n","Similarity(doc): 0.75\n","\n","------- Example 30 -------\n","Question 30: How long has Tom been with the company?\n","Original answer: 3 years\n","Predicted answer(conv): over 3 years\n","Predicted answer(doc): over 3 years\n","F1 score(conv): 0.8\n","F1 score(doc): 0.8\n","Similarity(conv): 0.88\n","Similarity(doc): 0.88\n","\n","------- Example 31 -------\n","Question 31: What type of cookies has Jerry baked?\n","Original answer: mint chocolate chip\n","Predicted answer(conv): mint chocolate chips\n","Predicted answer(doc): mint chocolate chips\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.93\n","Similarity(doc): 0.93\n","\n","------- Example 32 -------\n","Question 32: What dessert does Jerry look forward to on Thanksgiving?\n","Original answer: pumpkin pie\n","Predicted answer(conv): pumpkin pie\n","Predicted answer(doc): pumpkin pie\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 33 -------\n","Question 33: What kind of doctor does Tom want to be?\n","Original answer: brain surgeon\n","Predicted answer(conv): brain surgeon\n","Predicted answer(doc): brain surgeon\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 34 -------\n","Question 34: Which island in Hawaii is Tom visiting?\n","Original answer: maui\n","Predicted answer(conv): mauii\n","Predicted answer(doc): mauii\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.89\n","Similarity(doc): 0.89\n","\n","------- Example 35 -------\n","Question 35: What kind of latte did Jerry get?\n","Original answer: matcha\n","Predicted answer(conv): matcha\n","Predicted answer(doc): matcha\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 36 -------\n","Question 36: What does Jerry think about human-like chatbots?\n","Original answer: great conversationalists\n","Predicted answer(conv): i can't wait for them to be great conversationalists\n","Predicted answer(doc): i can't wait for them to be great conversationalists\n","F1 score(conv): 0.36\n","F1 score(doc): 0.36\n","Similarity(conv): 0.68\n","Similarity(doc): 0.68\n","\n","------- Example 37 -------\n","Question 37: Where is Jerry going skiing for the holidays?\n","Original answer: tahoe\n","Predicted answer(conv): tahoe\n","Predicted answer(doc): tahoe\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 38 -------\n","Question 38: What type of painting does Tom do?\n","Original answer: oil\n","Predicted answer(conv): oil painting\n","Predicted answer(doc): oil painting\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.61\n","Similarity(doc): 0.61\n","\n","------- Example 39 -------\n","Question 39: Where did Jerry's family move after being scammed?\n","Original answer: taiwan\n","Predicted answer(conv): taiwan\n","Predicted answer(doc): taiwan\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 40 -------\n","Question 40: Where did Tom visit last week?\n","Original answer: grand canyon\n","Predicted answer(conv): sf, grand canyon and vegas\n","Predicted answer(doc): sf, grand canyon and vegas\n","F1 score(conv): 0.57\n","F1 score(doc): 0.57\n","Similarity(conv): 0.75\n","Similarity(doc): 0.75\n","\n","------- Example 41 -------\n","Question 41: What has Tom been working on with his mentor?\n","Original answer: communication\n","Predicted answer(conv): communication skills\n","Predicted answer(doc): communication skills\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.7\n","Similarity(doc): 0.7\n","\n","------- Example 42 -------\n","Question 42: What is Jerry scared about?\n","Original answer: cooking\n","Predicted answer(conv): i have to cook dinner for some friends tonight\n","Predicted answer(doc): i have to cook dinner for some friends tonight\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.6\n","Similarity(doc): 0.6\n","\n","------- Example 43 -------\n","Question 43: Who does Tom like now?\n","Original answer: john mayer\n","Predicted answer(conv): john mayer\n","Predicted answer(doc): john mayer\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 44 -------\n","Question 44: Who invited Tom for lunch?\n","Original answer: partner's friend\n","Predicted answer(conv): my partner's former friend\n","Predicted answer(doc): my partner's former friend\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.8\n","Similarity(doc): 0.8\n","\n","------- Example 45 -------\n","Question 45: Where is Jerry's family?\n","Original answer: india\n","Predicted answer(conv): new york\n","Predicted answer(doc): new york\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.44\n","Similarity(doc): 0.44\n","\n","------- Example 46 -------\n","Question 46: What did Jerry have for lunch?\n","Original answer: mussels\n","Predicted answer(conv): garbanzo fritters and mussels\n","Predicted answer(doc): garbanzo fritters and mussels\n","F1 score(conv): 0.4\n","F1 score(doc): 0.4\n","Similarity(conv): 0.77\n","Similarity(doc): 0.77\n","\n","------- Example 47 -------\n","Question 47: What is Jerry excited to watch live?\n","Original answer: sharks\n","Predicted answer(conv): \n","Predicted answer(doc): \n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.31\n","Similarity(doc): 0.31\n","\n","------- Example 48 -------\n","Question 48: Where in Europe does Jerry plan to visit?\n","Original answer: france\n","Predicted answer(conv): france, germany, or italy\n","Predicted answer(doc): france, germany, or italy\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.7\n","Similarity(doc): 0.7\n","\n","------- Example 49 -------\n","Question 49: Where does Jerry visit every few weeks?\n","Original answer: san francisco\n","Predicted answer(conv): new york\n","Predicted answer(doc): new york\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.59\n","Similarity(doc): 0.59\n","\n","------- Example 50 -------\n","Question 50: Where did Jerry live before moving?\n","Original answer: upstate new york\n","Predicted answer(conv): upstate new york\n","Predicted answer(doc): upstate new york\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 51 -------\n","Question 51: What type of marathons does Tom run every month?\n","Original answer: half-marathon\n","Predicted answer(conv): half - marathon\n","Predicted answer(doc): half - marathon\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 52 -------\n","Question 52: What game did Tom win?\n","Original answer: pingpong\n","Predicted answer(conv): pingpong\n","Predicted answer(doc): pingpong\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 53 -------\n","Question 53: What type of food does Jerry prefer?\n","Original answer: spicy\n","Predicted answer(conv): asian food prefer spicy\n","Predicted answer(doc): asian food prefer spicy\n","F1 score(conv): 0.4\n","F1 score(doc): 0.4\n","Similarity(conv): 0.62\n","Similarity(doc): 0.62\n","\n","------- Example 54 -------\n","Question 54: What type of Japanese food does Jerry love?\n","Original answer: sushi\n","Predicted answer(conv): sushi\n","Predicted answer(doc): sushi\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 55 -------\n","Question 55: What places does Jerry plan to visit?\n","Original answer: australia\n","Predicted answer(conv): australia and new zealand\n","Predicted answer(doc): australia and new zealand\n","F1 score(conv): 0.4\n","F1 score(doc): 0.4\n","Similarity(conv): 0.71\n","Similarity(doc): 0.71\n","\n","------- Example 56 -------\n","Question 56: What type of workout did Tom do at the gym?\n","Original answer: weight lifting\n","Predicted answer(conv): weight lifting\n","Predicted answer(doc): weight lifting\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 57 -------\n","Question 57: What book is Tom reading?\n","Original answer: the three body problem\n","Predicted answer(conv): the three body problem\n","Predicted answer(doc): the three body problem\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 58 -------\n","Question 58: What movie did Jerry watch over the weekend?\n","Original answer: knives out\n","Predicted answer(conv): knives out\n","Predicted answer(doc): knives out\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 59 -------\n","Question 59: What Pokémon does Jerry like?\n","Original answer: jigglypuff\n","Predicted answer(conv): jigglypuff\n","Predicted answer(doc): jigglypuff\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 60 -------\n","Question 60: What is Jerry’s favorite movie?\n","Original answer: avatar\n","Predicted answer(conv): avatar\n","Predicted answer(doc): avatar\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 61 -------\n","Question 61: Where is Tom planning to go around Christmas?\n","Original answer: disneyland\n","Predicted answer(conv): disneyland trip around christmas? jerry : oh wow, that sounds like so much fun! definitely count us in. what is your plan? tom : tentative plan is to drive to la on 23rd and then stay at the disney resort\n","Predicted answer(doc): disneyland trip around christmas?'jerry said'oh wow, that sounds like so much fun! definitely count us in. what is your plan?'tom said'tentative plan is to drive to la on 23rd and then stay at the disney resort\n","F1 score(conv): 0.05\n","F1 score(doc): 0.05\n","Similarity(conv): 0.6\n","Similarity(doc): 0.61\n","\n","------- Example 62 -------\n","Question 62: What board game has Tom been playing lately?\n","Original answer: game of thrones\n","Predicted answer(conv): games of thrones\n","Predicted answer(doc): games of thrones\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.99\n","Similarity(doc): 0.99\n","\n","------- Example 63 -------\n","Question 63: What broke down on Tom’s way to work?\n","Original answer: moped\n","Predicted answer(conv): my moped\n","Predicted answer(doc): my moped\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.9\n","Similarity(doc): 0.9\n","\n","------- Example 64 -------\n","Question 64: What event does Tom like participating in?\n","Original answer: spartan race\n","Predicted answer(conv): spartan race\n","Predicted answer(doc): spartan race\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 65 -------\n","Question 65: Where is Tom taking a skydiving lesson?\n","Original answer: seville\n","Predicted answer(conv): seville, spain\n","Predicted answer(doc): seville, spain\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.91\n","Similarity(doc): 0.91\n","\n","------- Example 66 -------\n","Question 66: What course content does Tom find up-to-date?\n","Original answer: latest research findings\n","Predicted answer(conv): latest research findings\n","Predicted answer(doc): latest research findings\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 67 -------\n","Question 67: What game did Jerry play at the party?\n","Original answer: pictionary\n","Predicted answer(conv): pictionary\n","Predicted answer(doc): pictionary\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 68 -------\n","Question 68: What software does Jerry use for music composition?\n","Original answer: logic pro x\n","Predicted answer(conv): logic pro x\n","Predicted answer(doc): logic pro x\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 69 -------\n","Question 69: What diet is Tom trying?\n","Original answer: keto\n","Predicted answer(conv): keto\n","Predicted answer(doc): keto\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 70 -------\n","Question 70: What is Jerry’s book about?\n","Original answer: fresh outlook\n","Predicted answer(conv): 24 days of advent\n","Predicted answer(doc): 24 days of advent\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.15\n","Similarity(doc): 0.15\n","\n","------- Example 71 -------\n","Question 71: What game is Tom going to watch?\n","Original answer: warriors vs. grizzlies\n","Predicted answer(conv): basketball game. hope your headache goes away! jerry : haha, thanks! never get them, so it's super weird who's playing? tom : hmm, try taking some < redacted _ term >! i'm going to see the warriors vs. the grizzlies\n","Predicted answer(doc): basketball game. hope your headache goes away!'jerry said'haha, thanks! never get them, so it's super weird who's playing?'tom said'hmm, try taking some < redacted _ term >! i'm going to see the warriors vs. the grizzlies\n","F1 score(conv): 0.14\n","F1 score(doc): 0.15\n","Similarity(conv): 0.57\n","Similarity(doc): 0.59\n","\n","------- Example 72 -------\n","Question 72: What game is Jerry excited about?\n","Original answer: giants game\n","Predicted answer(conv): giants game\n","Predicted answer(doc): giants game\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 73 -------\n","Question 73: Where does Tom work?\n","Original answer: palo alto\n","Predicted answer(conv): palo alto\n","Predicted answer(doc): palo alto\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 74 -------\n","Question 74: What is Jerry’s favorite word origin?\n","Original answer: gymnasium\n","Predicted answer(conv): gymnasium and jazz\n","Predicted answer(doc): gymnasium and jazz\n","F1 score(conv): 0.5\n","F1 score(doc): 0.5\n","Similarity(conv): 0.77\n","Similarity(doc): 0.77\n","\n","------- Example 75 -------\n","Question 75: What flavored water did Tom drink?\n","Original answer: watermelon\n","Predicted answer(conv): watermelon\n","Predicted answer(doc): watermelon\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 76 -------\n","Question 76: What type of cake does Tom prefer?\n","Original answer: chocolate cake + vanilla icing\n","Predicted answer(conv): classic carrot cake\n","Predicted answer(doc): classic carrot cake\n","F1 score(conv): 0.25\n","F1 score(doc): 0.25\n","Similarity(conv): 0.43\n","Similarity(doc): 0.43\n","\n","------- Example 77 -------\n","Question 77: Where did Jerry study English?\n","Original answer: new york city\n","Predicted answer(conv): us\n","Predicted answer(doc): us\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.5\n","Similarity(doc): 0.5\n","\n","------- Example 78 -------\n","Question 78: Where did Jerry travel last weekend?\n","Original answer: vietnam and hongkong\n","Predicted answer(conv): vietnam and hongkong\n","Predicted answer(doc): vietnam and hongkong\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 79 -------\n","Question 79: What language did Jerry grow up speaking?\n","Original answer: french\n","Predicted answer(conv): french\n","Predicted answer(doc): french\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 80 -------\n","Question 80: Where is Tom's cigar from?\n","Original answer: peru\n","Predicted answer(conv): peru\n","Predicted answer(doc): peru\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 81 -------\n","Question 81: What Netflix show does Jerry recommend?\n","Original answer: white collar\n","Predicted answer(conv): white collar\n","Predicted answer(doc): white collar\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 82 -------\n","Question 82: What is Jerry’s favorite cuisine?\n","Original answer: hunan\n","Predicted answer(conv): chinese\n","Predicted answer(doc): chinese\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.51\n","Similarity(doc): 0.51\n","\n","------- Example 83 -------\n","Question 83: Where did Jerry travel recently?\n","Original answer: mozambique\n","Predicted answer(conv): mozambique\n","Predicted answer(doc): mozambique\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 84 -------\n","Question 84: What book is Jerry currently reading?\n","Original answer: why we sleep\n","Predicted answer(conv): why we sleep\n","Predicted answer(doc): why we sleep\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 85 -------\n","Question 85: What book is Tom planning to read?\n","Original answer: something deeply hidden\n","Predicted answer(conv): something deeply hidden by sean carroll\n","Predicted answer(doc): something deeply hidden by sean carroll\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.69\n","Similarity(doc): 0.69\n","\n","------- Example 86 -------\n","Question 86: Which event does Jerry want to help with?\n","Original answer: badminton\n","Predicted answer(conv): badminton + tennis + basketball\n","Predicted answer(doc): \n","F1 score(conv): 0.33\n","F1 score(doc): 0.0\n","Similarity(conv): 0.79\n","Similarity(doc): 0.2\n","\n","------- Example 87 -------\n","Question 87: What does Jerry do for work?\n","Original answer: acupuncturist\n","Predicted answer(conv): comic\n","Predicted answer(doc): comic\n","F1 score(conv): 0.0\n","F1 score(doc): 0.0\n","Similarity(conv): 0.08\n","Similarity(doc): 0.08\n","\n","------- Example 88 -------\n","Question 88: What fish does Jerry's research focus on?\n","Original answer: jellyfish and pufferfish\n","Predicted answer(conv): jellyfish and pufferfish\n","Predicted answer(doc): jellyfish and pufferfish\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 89 -------\n","Question 89: Where is Jerry traveling this weekend?\n","Original answer: vancouver\n","Predicted answer(conv): vancouver\n","Predicted answer(doc): vancouver\n","F1 score(conv): 1.0\n","F1 score(doc): 1.0\n","Similarity(conv): 1.0\n","Similarity(doc): 1.0\n","\n","------- Example 90 -------\n","Question 90: What did Jerry eat for lunch?\n","Original answer: sandwich\n","Predicted answer(conv): a sandwich\n","Predicted answer(doc): a sandwich\n","F1 score(conv): 0.67\n","F1 score(doc): 0.67\n","Similarity(conv): 0.91\n","Similarity(doc): 0.91\n","\n","------- Example 91 -------\n","Question 91: Where is Tom's hometown?\n","Original answer: north coast of france\n","Predicted answer(conv): on the north coast of france\n","Predicted answer(doc): north coast of france\n","F1 score(conv): 0.8\n","F1 score(doc): 1.0\n","Similarity(conv): 0.93\n","Similarity(doc): 1.0\n","\n","\n","Average F1 score(conv): 0.6691550999508654\n","Average F1 score(doc): 0.6738475569997309\n","Average Similarity(conv): 0.8339243979071793\n","Average Similarity(doc): 0.8372283381126497\n"]}]}]}